{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Edit Metadata",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "elections.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gokulbot/ProbabilityDistributions-ai1-fall2019/blob/master/elections.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gS4v6900fO2M",
        "colab_type": "text"
      },
      "source": [
        "# Pandas, Statistics, And Elections"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "hide": true,
        "id": "ZZ8OoTbkfO2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import matplotlib as mpl\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn.apionly as sns # conda install seaborn or pip install seaborn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQrNHR59fO2W",
        "colab_type": "text"
      },
      "source": [
        "### Random Variables\n",
        "\n",
        "A **random variable** is a mapping from a sample space to the set of real numbers. It assigns a real number to each outcome in the sample space.\n",
        "\n",
        "For example, consider the event of a coin toss that we have seen before. There are two outcomes in the sample space, a heads and a tails. We can ask the question, whats the probability of a heads or a tails? For an unbiased coin, these are, by symmetry, 1/2 each. The random variable here is the number of heads, and its probability is P(0)=1/2, and P(1)=1/2.\n",
        "\n",
        "Another random variable is the number of heads in two coin tosses. There, as we have seen before, P(0)=1/4, P(1)=1/2, P(2)=1/4.\n",
        "\n",
        "Random variables provide the link from events and sample spaces to data, and it is their **probability distribution** that we are interested in.\n",
        "\n",
        "A random variable is called **discrete** if it has a countable number of values. The technical definition of countable is that there is a 1-1 correspondence with the integers 1,2,3... . The number of heads in 2 coin tosses is a discrete random variable.\n",
        "\n",
        "#### Bernoulli Random Variables\n",
        "\n",
        "The **Bernoulli Distribution** represents the distribution for coin flips. Let the random variable X represent such a coin flip, where X=1 is heads, and X=0 is tails. Let us further say that the probability of heads is p (p=0.5 is a fair coin). \n",
        "\n",
        "We then say:\n",
        "\n",
        "$$X \\sim Bernoulli(p),$$\n",
        "\n",
        "which is to be read as **X has distribution Bernoulli(p)**. The **probability distribution function (pdf)** or **probability mass function** associated with the Bernoulli distribution is\n",
        "\n",
        "\\begin{eqnarray}\n",
        "P(X = 1) &=& p \\\\\n",
        "P(X = 0) &=& 1 - p \n",
        "\\end{eqnarray}\n",
        "\n",
        "for p in the range 0 to 1. \n",
        "The **pdf**, or the probability that random variable $X=x$ may thus be written as \n",
        "\n",
        "$$P(X=x) = p^x(1-p)^{1-x}$$\n",
        "\n",
        "for x in the set {0,1}.\n",
        "\n",
        "The **mean**, or **expected value** of this distribution can be calculated analogously to the mean value of data by noting that $X=1$ happens with frequency $p*N$ and thus it is p. \n",
        "\n",
        "Let us engage in some term defining right now, since we will use these terms throught the book. $X$ is a random variable, and when we say $X=x$ we are asking \"*what if the random variable X takes the value x*. \n",
        "\n",
        "$P(X=x)$ asks: what is the probability that the random variable X takes the value x. \n",
        "\n",
        "Finally $p$ is a parameter of the Bernoulli distribution, and as we have seen, one of the things we want to do in data analysis is: having seen some data, what can we infer to be the values of p, so that we can make future predictions for X."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koiubQMufO2X",
        "colab_type": "text"
      },
      "source": [
        "## Dataframes with Pandas\n",
        "\n",
        "For reference, here is a useful [pandas cheat sheet](https://drive.google.com/folderview?id=0ByIrJAE4KMTtaGhRcXkxNHhmY2M&usp=sharing).\n",
        "\n",
        "Often data is stored in comma separated values (CSV) files. CSV files can be output by any spreadsheet software, and are plain text, hence are a great way to share data.\n",
        "\n",
        "Here we are reading in a spreadsheet of the number of electoral votes in the American Electoral College."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UqA-Ii8hYrK",
        "colab_type": "code",
        "outputId": "525220cf-ada3-4294-b41c-56ae9142c9d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!git clone https://github.com/gokulbot/ProbabilityDistributions-ai1-fall2019.git"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'ProbabilityDistributions-ai1-fall2019' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kR8c_Xbbhk-3",
        "colab_type": "code",
        "outputId": "c96ca521-b3fe-4c57-c157-8ec2b4a9bc16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pwd\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr6F87MGh8mm",
        "colab_type": "code",
        "outputId": "71879a66-cfd6-4680-f378-299c5c926f91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!ls ProbabilityDistributions-ai1-fall2019\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "binder\telections.ipynb  lecture.md   README.md\t\t   statesplot.py\n",
            "data\timages\t\t lecture.pdf  samplingcoins.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fynNSQZiJ2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cp -a ProbabilityDistributions-ai1-fall2019/data ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5p2qIdzLiZs3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cp -a ProbabilityDistributions-ai1-fall2019/statesplot.py ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGIqlz4Dip2r",
        "colab_type": "code",
        "outputId": "cca5f557-8297-4832-cf74-27dc49f3e373",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data  ProbabilityDistributions-ai1-fall2019  sample_data  statesplot.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8L-lZo_fO2Y",
        "colab_type": "code",
        "outputId": "3fc2a288-6e85-4c6a-87c8-661176d7571c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "electoral_votes = pd.read_csv(\"data/electoral_votes.csv\")\n",
        "electoral_votes.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>State</th>\n",
              "      <th>Votes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>California</td>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Texas</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>New York</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Florida</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Illinois</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        State  Votes\n",
              "0  California     55\n",
              "1       Texas     38\n",
              "2    New York     29\n",
              "3     Florida     29\n",
              "4    Illinois     20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOeaYdIMkCHv",
        "colab_type": "code",
        "outputId": "1b8ce008-8122-45d4-93f7-ace7474bc3d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(electoral_votes)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zav4NH6XfO2b",
        "colab_type": "text"
      },
      "source": [
        "`electoral_votes` is a dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIwBj5TFfO2c",
        "colab_type": "text"
      },
      "source": [
        "The actual file looks something like this:\n",
        "\n",
        "```\n",
        "State,Votes\n",
        "California,55\n",
        "Texas,38\n",
        "New York,29\n",
        "Florida,29\n",
        "Illinois,20\n",
        "Pennsylvania,20\n",
        "```\n",
        "You can see that an index has been added, and its numerical, and starts at 0 (like in the lists). This index is not particularly useful, so lets set the state column as the index."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZCXhyzHfO2d",
        "colab_type": "code",
        "outputId": "6a2235b5-8781-478c-97c1-7af558a73dcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "electoral_votes = electoral_votes.set_index('State')\n",
        "electoral_votes.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Votes</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>State</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>California</th>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Texas</th>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>New York</th>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Florida</th>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Illinois</th>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Votes\n",
              "State            \n",
              "California     55\n",
              "Texas          38\n",
              "New York       29\n",
              "Florida        29\n",
              "Illinois       20"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWgHI9rtfO2g",
        "colab_type": "text"
      },
      "source": [
        "Notice how we used the `electoral_votes` variable twice in a line above. Pandas returns new objects in memory when we do something to a dataframe (here, setting the index). We relabel the new memory with the same label.\n",
        "\n",
        "What happens to the old memory? When nothing refers to it, Python \"garbage collects\" it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyCx4EB1fO2h",
        "colab_type": "text"
      },
      "source": [
        "#### The Predictwise distribution revisited\n",
        "\n",
        "Let is go to Predictiwise election predictions. There, on OCt 8 2012, we took a set of probabilities, one per state that Predictwise gave us on October 12th to make a prediction of the \"empirical\" distribution of votes that Obama would get, come election day.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMK7bc3zfO2h",
        "colab_type": "code",
        "outputId": "3374efc6-fe98-45c3-8d06-4555a7ac210a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "predictwise = pd.read_csv('data/predictwise.csv').set_index('States')\n",
        "predictwise.head()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Obama</th>\n",
              "      <th>Romney</th>\n",
              "      <th>Votes</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>States</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Alabama</th>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Alaska</th>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Arizona</th>\n",
              "      <td>0.062</td>\n",
              "      <td>0.938</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Arkansas</th>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>California</th>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Obama  Romney  Votes\n",
              "States                          \n",
              "Alabama     0.000   1.000      9\n",
              "Alaska      0.000   1.000      3\n",
              "Arizona     0.062   0.938     11\n",
              "Arkansas    0.000   1.000      6\n",
              "California  1.000   0.000     55"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTopfVlUmInW",
        "colab_type": "code",
        "outputId": "110807d1-91fe-4969-df23-a9747cc07678",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predictwise.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(51, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXEX3Q5tmbya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictwise.dtypes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_W3Eoy3mtn9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictwise.loc['Texas']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAO7HnaKnMJY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alist=[1,2,3,4,5,6]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9Z_uZMuvCM9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "77c83ae7-7481-4f45-a698-0071a30412b3"
      },
      "source": [
        "predictwise['Obama'].values.reshape(-1,1).shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(51, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLG5pnOMnUu2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alist[1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l24VM0-enwXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alist[:-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bX1QBNSIn8y1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alist[2:3]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "as2cPNohoEOT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sqauredlist= [n*n for n in alist]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oj6t7Bknol-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sqauredlist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RApUYUqSoqZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "anp=np.array([1,2,3,4,5])\n",
        "nm= np.array([0,8,9,7,6])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIn4x-HhpDJg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.dot(anp,nm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fXGdRxcpLBp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bias= 5\n",
        "sigmoid = lambda x: 1/(1+np.exp(-x))\n",
        "sigmoid(np.dot(anp,nm)+ bias)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1W8JC3Zjo4o_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "counter= 0\n",
        "for i,ele in enumerate(anp) :\n",
        "  print(i,ele)\n",
        "  counter+= anp[i]*nm[i]\n",
        "counter  \n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8O7LQREqx9h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list(enumerate(anp))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPTrEqDJq3iP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "anp+nm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLndw8tpq-l1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "anp/5\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GzVLzDIrHdD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "twod = np.array([[1,2,3], [4,5,6]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pV7AdPZ6r31S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "twod[:,1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WRKulp9sAIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "twod"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDqIAag5sEEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.sum(twod)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RN6rzBQVsI-u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.sum(twod,axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxEWNBNUfO2k",
        "colab_type": "text"
      },
      "source": [
        "What we have now is a spreadsheet with indexed rows and named columns, called a dataframe in pandas.  \n",
        "\n",
        "`predictwise` is an instance of the pd.DataFrame class, created by calling the pd.read_csv \"constructor function\".\n",
        "\n",
        "`predictwise` is a dataframe object, and it has methods (functions) belonging to it. For example, `predictwise.head()` is a method that shows the first 5 rows of the dataframe.\n",
        "\n",
        "A pandas dataframe is a set of columns pasted together into a spreadsheet, as shown in the schematic below, which is taken from the cheatsheet above. The columns in pandas are called series objects.\n",
        "\n",
        "![](https://github.com/gokulbot/ProbabilityDistributions-ai1-fall2019/blob/master/images/pandastruct.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQBoxKVmzkDO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k=np.random.uniform(size=(51,10000))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPcblrY5z7bQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a= predictwise['Obama'].values.reshape(-1,1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rocJrRiI0JkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y=k<a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYwqA7Rn0dAE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "1fd4dfa1-b6eb-491f-e6f1-f7b14dfd6c22"
      },
      "source": [
        "y"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       ...,\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       [ True,  True,  True, ..., False,  True,  True],\n",
              "       [False, False, False, ..., False, False, False]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzgqfSmo0RDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "u=y*predictwise.Votes.values.reshape(-1,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBRNBWgc1i2e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "744abef7-f861-4667-ab37-51d2410a43a5"
      },
      "source": [
        "u"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, ...,  0,  0,  0],\n",
              "       [ 0,  0,  0, ...,  0,  0,  0],\n",
              "       [ 0,  0,  0, ...,  0,  0,  0],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ...,  0,  0,  0],\n",
              "       [10, 10, 10, ...,  0, 10, 10],\n",
              "       [ 0,  0,  0, ...,  0,  0,  0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8G5PRbsV3KkF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m= u.sum(axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIfgYPlR01u1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a=np.sum(m>=269)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjK0TjyV3_Ed",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "edd6ef99-514e-40bc-a209-bc9ed135b554"
      },
      "source": [
        "np.mean(a)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9964.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjFXP0Hs1FW7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "04b1b9d8-9dc8-4e6f-cde6-e8e6f2e36570"
      },
      "source": [
        "np.mean(u)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "276.48241960784316"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kC3BnV9asfDV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.hist(np.random.uniform(size=100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaP4R64uvqMm",
        "colab_type": "code",
        "outputId": "514f2633-2e84-4f63-80a1-6eed0483a22b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 898
        }
      },
      "source": [
        "predictwise['Obama'].values.reshape(-1,1)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.   ],\n",
              "       [0.   ],\n",
              "       [0.062],\n",
              "       [0.   ],\n",
              "       [1.   ],\n",
              "       [0.807],\n",
              "       [1.   ],\n",
              "       [1.   ],\n",
              "       [1.   ],\n",
              "       [0.72 ],\n",
              "       [0.004],\n",
              "       [1.   ],\n",
              "       [0.   ],\n",
              "       [1.   ],\n",
              "       [0.036],\n",
              "       [0.837],\n",
              "       [0.   ],\n",
              "       [0.   ],\n",
              "       [0.   ],\n",
              "       [1.   ],\n",
              "       [1.   ],\n",
              "       [1.   ],\n",
              "       [0.987],\n",
              "       [0.982],\n",
              "       [0.   ],\n",
              "       [0.074],\n",
              "       [0.046],\n",
              "       [0.   ],\n",
              "       [0.851],\n",
              "       [0.857],\n",
              "       [0.998],\n",
              "       [0.985],\n",
              "       [1.   ],\n",
              "       [0.349],\n",
              "       [0.025],\n",
              "       [0.89 ],\n",
              "       [0.   ],\n",
              "       [0.976],\n",
              "       [0.978],\n",
              "       [1.   ],\n",
              "       [0.   ],\n",
              "       [0.001],\n",
              "       [0.001],\n",
              "       [0.   ],\n",
              "       [0.   ],\n",
              "       [1.   ],\n",
              "       [0.798],\n",
              "       [0.999],\n",
              "       [0.002],\n",
              "       [0.925],\n",
              "       [0.   ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kja1CJa9sf4Q",
        "colab_type": "code",
        "outputId": "4449837e-e33f-4727-b325-2056c0948234",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "n=(np.random.uniform(size=(51,10000)) < predictwise['Obama'].values.reshape(-1,1))\n",
        "n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       ...,\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       [ True,  True,  True, ...,  True,  True,  True],\n",
              "       [False, False, False, ..., False, False, False]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-WSSZycz5qF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWq85JYdsgHA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "d08547bb-6304-4aed-c224-9581d8480298"
      },
      "source": [
        "p= n*predictwise.Votes.values.reshape(-1, 1).sum(axis=0)\n",
        "p\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,   0,   0],\n",
              "       [  0,   0,   0, ...,   0,   0,   0],\n",
              "       [  0,   0,   0, ...,   0,   0,   0],\n",
              "       ...,\n",
              "       [  0,   0,   0, ...,   0,   0,   0],\n",
              "       [538, 538, 538, ..., 538, 538, 538],\n",
              "       [  0,   0,   0, ...,   0,   0,   0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0L40EPCCfO2k",
        "colab_type": "text"
      },
      "source": [
        "## Simulate an election"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "havAzaMmfO2l",
        "colab_type": "code",
        "outputId": "31aa7e4d-ee4a-4ad7-8af4-858530663093",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def simulate_election(model, n_sim):\n",
        "    simulations = np.random.uniform(size=(51, n_sim))\n",
        "    obama_votes = (simulations < model.Obama.values.reshape(-1, 1)) * model.Votes.values.reshape(-1, 1)\n",
        "    #summing over rows gives the total electoral votes for each simulation\n",
        "    return obama_votes.sum(axis=0)\n",
        "result = simulate_election(predictwise, 10000)\n",
        "np.sum(result >= 269)) #run multiple times to see result change"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9962.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yimaUek19VV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "341d5570-a76f-4474-a007-9ab0e2c7fc56"
      },
      "source": [
        "  simulations = np.random.uniform(size=(51, 10000))\n",
        "  obama_votes = (simulations < predictwise.Obama.values.reshape(-1, 1)) * predictwise.Votes.values.reshape(-1, 1)\n",
        "  obama_votes"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, ...,  0,  0,  0],\n",
              "       [ 0,  0,  0, ...,  0,  0,  0],\n",
              "       [ 0,  0,  0, ...,  0,  0,  0],\n",
              "       ...,\n",
              "       [ 0,  0,  0, ...,  0,  0,  0],\n",
              "       [10, 10,  0, ...,  0, 10, 10],\n",
              "       [ 0,  0,  0, ...,  0,  0,  0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAmPJOCjsd9A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6be13078-81ed-497d-d436-a4d1668b464a"
      },
      "source": [
        "p= obama_votes.sum(axis=0)\n",
        "p #np.mean(np.sum(p >= 269))"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([303, 297, 322, ..., 298, 312, 314])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxbhZ5CgfO2p",
        "colab_type": "text"
      },
      "source": [
        "Let us parse the intent of the above code a bit. We run 10,000 simulations. In each one of these simulations, we toss 51 different biased coins, and assign the vote to obama is the output of `np.random.uniform` is less than the probablity of an obama win. \n",
        "\n",
        "The first thing to pick up on here is that `np.random.uniform` gives you a random number between 0 and 1, uniformly. In other words, the number is equally likely to be between 0 and 0.1, 0.1 and 0.2, and so on. This is a very intuitive idea, but it is formalized by the notion of the **Uniform Distribution**.\n",
        "\n",
        "We then say:\n",
        "\n",
        "$$X \\sim Uniform([0,1),$$\n",
        "\n",
        "which is to be read as **X has distribution Uniform([0,1])**. The **probability distribution function (pdf)** associated with the Uniform distribution is\n",
        "\n",
        "\\begin{eqnarray}\n",
        "P(X = x) &=& 1 \\, for \\, x \\in [0,1] \\\\\n",
        "P(X = x) &=& 0 \\, for \\, x \\notin [0,1]\n",
        "\\end{eqnarray}\n",
        "\n",
        "We use this trick of sampling from a Uniform distribution ti sumulate multiple draws from each of the 51 bernoulli distribitions we have, one for each state.\n",
        "\n",
        "Now for any Obama probability less than 1.0, there are simulations in which Obama wont win that state, and this will induce fluctuations and a distribution on the total number of electoral college votes that Obama gets (when we sum over all states). And this is what we see in the histogram below. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "figure_type": "m",
        "id": "awgs1atXfO2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_simulation(simulation):    \n",
        "    plt.hist(simulation, bins=np.arange(200, 538, 1), \n",
        "             label='simulations', align='left', normed=True)\n",
        "    plt.axvline(332, 0, .5, color='r', label='Actual Outcome')\n",
        "    plt.axvline(269, 0, .5, color='k', label='Victory Threshold')\n",
        "    p05 = np.percentile(simulation, 5.)\n",
        "    p95 = np.percentile(simulation, 95.)\n",
        "    iq = int(p95 - p05)\n",
        "    pwin = ((simulation >= 269).mean() * 100)\n",
        "    plt.title(\"Chance of Obama Victory: %0.2f%%, Spread: %d votes\" % (pwin, iq))\n",
        "    plt.legend(frameon=False, loc='upper left')\n",
        "    plt.xlabel(\"Obama Electoral College Votes\")\n",
        "    plt.ylabel(\"Probability\")\n",
        "    sns.despine()\n",
        "with sns.plotting_context('poster'):\n",
        "    plot_simulation(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuYWmvtmfO2s",
        "colab_type": "text"
      },
      "source": [
        "This is an empirical **Probability Mass Function** or **Probability Density Function**. The concept of Mass Function is used when the outcomes come from a discrete set, rather than a continuous set. The word **density** is strictly used when the random variable X takes on continuous values, as in the uniform distribution, rather than discrete values such as here, but we'll abuse the language and use the word probability distribution in both cases.\n",
        "\n",
        "Lets summarize: the way the density arose here that we did ran 10,000 tosses (for each state), and depending on the value, assigned the state to Obama or Romney, and then summed up the electoral votes over the states.\n",
        "\n",
        "There is a second, very useful question, we can ask of any such probability density: what is the probability that a random variable is less than some value. In other words: $P(X < x)$. This is *also* a probability distribution and is called the **Cumulative Distribution Function**, or CDF (sometimes just called the **distribution**, as opposed to the **density**). Its obtained by \"summing\" the probability density function for all $X$ less than $x$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIdoM3B4fO2t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CDF = lambda x: np.float(np.sum(result < x))/result.shape[0]\n",
        "for votes in [200, 300, 320, 340, 360, 400, 500]:\n",
        "    print(\"Obama Win CDF at votes=\", votes, \" is \", CDF(votes))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "figure_type": "m",
        "id": "uAf7hLHHfO2v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "votelist=np.arange(0, 540, 5)\n",
        "plt.plot(votelist, [CDF(v) for v in votelist], '.-');\n",
        "plt.xlim([200,400])\n",
        "plt.xlabel(\"votes for Obama\")\n",
        "plt.ylabel(\"probability of Obama win\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOlN8lcTfO2x",
        "colab_type": "text"
      },
      "source": [
        "### The Gaussian Distribution\n",
        "\n",
        "The sampling distribution of the mean itself has a mean $\\mu$ and variance $s^2 = \\frac{\\sigma^2}{N}$. This distribution is called the **Gaussian** or **Normal Distribution**, and is probably the most important distribution in all of statistics.\n",
        "\n",
        "The probability density of the normal distribution is given as:\n",
        "\n",
        "$$ N(x, \\mu, \\sigma) = \\frac{1}{s\\sqrt{2\\pi}} e^{ -\\frac{(x-\\mu)^2}{2s^2} } .$$\n",
        "\n",
        "$s$ is called the **standard error**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eRHxLZAfO2x",
        "colab_type": "text"
      },
      "source": [
        "Lets step back and try and think about what this all means. As an example, say I have a weight-watchers' study of 1000 people, whose average weight is 150 lbs with standard deviation of 30lbs. If I was to randomly choose many samples of 100 people each, the mean weights of those samples would cluster around 150lbs with a standard error of 30/$\\sqrt{100}$ = 3lbs. Now if i gave you a different sample of 100 people with an average weight of 170lbs, this weight would be more than 6 standard errors beyond the population mean, ^[this example is motivated by the crazy bus example in Charles Whelan's excellent Naked Statistics Book] and would thus be very unlikely to be from the weight watchers group."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvMu26kkfO2y",
        "colab_type": "text"
      },
      "source": [
        "The expected value of the Gaussian distribution is $E[X]=\\mu$ and the variance is $Var[X]=s^2$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Lefy4BUfO2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "norm =  sp.stats.norm\n",
        "x = np.linspace(-5,5, num=200)\n",
        "colors=sns.color_palette()\n",
        "\n",
        "fig = plt.figure(figsize=(12,6))\n",
        "for mu, s, c in zip([0.5]*3, [0.2, 0.5, 0.8], colors):\n",
        "    plt.plot(x, norm.pdf(x, mu, s), lw=2, \n",
        "             c=c, label = r\"$\\mu = {0:.1f}, s={1:.1f}$\".format(mu, s))\n",
        "    plt.fill_between(x, norm.pdf(x, mu, s), color=c, alpha = .4)\n",
        "    \n",
        "    \n",
        "plt.xlim([-5,5])\n",
        "plt.legend(loc=0)\n",
        "plt.ylabel(\"PDF at $x$\")\n",
        "plt.xlabel(\"$x$\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgjTuj7VfO20",
        "colab_type": "text"
      },
      "source": [
        "### The Central Limit Theorem\n",
        "\n",
        "The reason for the distribution's importance is the Central Limit Theorem(CLT). The theorem is stated as thus, very similar to the law of large numbers:\n",
        "\n",
        "**Let $x_1,x_2,...,x_n$ be a sequence of independent, identically-distributed (IID) random variables from a random variable $X$. Suppose that $X$ has the finite mean $\\mu$ AND finite variance $\\sigma^2$. Then the average of the first n of them:**\n",
        "\n",
        "$$S_n = \\frac{1}{n} \\sum_{i=1}^{n} x_i ,$$\n",
        "\n",
        "**converges to a Gaussian Random Variable with mean $\\mu$ and variance $\\sigma^2/n$ as $n \\to \\infty$:**\n",
        "\n",
        "$$ S_n \\sim N(\\mu,\\frac{\\sigma^2}{n}) \\, as \\, n \\to \\infty. $$\n",
        "\n",
        "In other words:\n",
        "\n",
        "$$s^2 = \\frac{\\sigma^2}{N}.$$\n",
        "\n",
        "\n",
        "This is true, *regardless* of the shape of $X$, which could be binomial, poisson, or any other distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOqCUO_hfO21",
        "colab_type": "text"
      },
      "source": [
        "Strictly speaking, under some conditions ^[REF :Lyapunov conditions], the variables $x_i$ dont have to be identically distributed, as long as $\\mu$ is the mean of the means and $\\sigma^2$ is the sum of the individual variances. This has major consequences, for the importance of this theorem.\n",
        "\n",
        "Many random variables can be thought of as having come from the sum of a large number of small and independent effects. For example human height or weight can be thought of as the sum as a large number of genetic and environmental factors, which add to increase or decrease height or weight respectively. Or think of a measurement of a height. There are lots of ways things could go wrong: frayed tapes, stretched tapes, smudged marks, bad lining up of the eye, etc. These are all independent and have no systematic error in one direction or the other.\n",
        "\n",
        "Then the sum of these factors, as long as there are a large number of them, will be distributed as a gaussian.\n",
        "\n",
        "As a rule of thumb, the CLT starts holding at $N \\sim 30$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIWU7XbsfO22",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "#### An application to elections: Binomial distribution in the large n, large k limit\n",
        "\n",
        "For example, consider the binomial distribution Binomial(n,k, p) in the limit of large n. The number of successes k in n trials can be ragarded as the sum of n IID Bernoulli variables with values 1 or 0. Obviously this is applicable to a large sequence of coin tosses, or to the binomial sampling issue that we encountered earlier in the case of the polling. \n",
        "\n",
        "Using the CLT we can replace the binomial distribution at large n by a gaussian where k is now a continuous variable, and whose mean is the mean of the binomial $np$ and whose variance is $np(1-p)$, since\n",
        "\n",
        "$$S_n \\sim N(p, \\frac{p(1-p)}{n}).$$\n",
        "\n",
        "The accuracy of this approximation depends on the variance. A large variance makes for a broad distribution spanning many discrete k, thus justifying the transition from a discrete to a continuous distribution.\n",
        "\n",
        "This approximation is used a lot in studying elections. For example, suppose I told you that I'd polled 1000 people in Ohio and found that 600 would vote Democratic, and 400 republican. Imagine that this 1000 is a \"sample\" drawn from the voting \"population\" of Ohio. Assume then that these are 1000 independent bernoulli trials with p=600/1000 = 0.6. Then we can say that, from the CLT, the mean of the sampling distribution of the mean of the bernoulli or equivalently the binomial is 0.6, with a variance of $0.6*0.4/1000 = 0.00024$. Thus the standard deviation is 0.015 for a mean of 0.6, or 1.5% on a mean of 60% voting Democratic.  This 1.5% if part of what pollsters quote as the margin of error of a candidates winning; they often include other factors such as errors in polling methodology.\n",
        "\n",
        "If one has results from multiple pollsters, one can treat them as independent samples from the voting population. Then the average from these samples will approach the average in the population, with the sample means distributed normally around it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z74qkaJTfO23",
        "colab_type": "text"
      },
      "source": [
        "#### What does this all mean?\n",
        "\n",
        "The sample mean, or mean of the random variables $x_{mi}$ in the sample $m$, has a sampling distribution with mean $\\mu$ and variance $\\frac{\\sigma^2}{N}$, as shown before. Now for large sample sizes we can go further and use the CLT theorem to say that this distribution is the normal distribution,\n",
        "\n",
        "$$S_N \\sim N(\\mu, \\frac{\\sigma^2}{N})$$.\n",
        "\n",
        "The preciseness of saying that we have a gaussian is a huge gain in our expository power. For example, for the case of the weight-watchers program above, a separation of 20lbs is more than 3 standard errors away, which corresponds to being way in the tail of a gaussian distribution. Because we can now quantify the area under the curve, we can say that 99.7\\% of the sample means lie within 9lbs of 150. Thus you can way easily reject the possibility that the new sample is from the weight-watchers program with 99.7\\% confidence. \n",
        "\n",
        "Indeed, the CLT allows us to take the reduction in variance we get from large samples, and make statements in different cases that are quite strong:\n",
        "\n",
        "1. if we know a lot about the population, and randomly sampled 100 points from it, the sample mean would be with 99.7\\% confidence within $0.3\\sigma$ of the population mean. And thus, if $\\sigma$ is small, the sample mean is quite representative of the population mean.\n",
        "2. The reverse: if we have a well sampled 100 data points, we could make strong statements about the population as a whole. This is indeed how election polling and other sampling works. \n",
        "3. we can infer, as we just did, if a sample is consistent with a population\n",
        "4. by the same token, you can compare two samples and infer if they are from the same population."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiWgAWX2fO23",
        "colab_type": "text"
      },
      "source": [
        "### An application: Gallup Party Affiliation Poll\n",
        "\n",
        "Earlier we had used the Predictwise probabilities from Octover 12th to create a predictive model for the elections. This time, armed with what we have learnt in this chapter, we will try to **estimate** our own win probabilities to plug into our predictive model.\n",
        "\n",
        "We will start with a simple forecast model. We will try to predict the outcome of the election based the estimated proportion of people in each state who identify with one one political party or the other.\n",
        "\n",
        "Gallup measures the political leaning of each state, based on asking random people which party they identify or affiliate with. [Here's the data](http://www.gallup.com/poll/156437/heavily-democratic-states-concentrated-east.aspx#2) they collected from January-June of 2012:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7sspsGCfO24",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gallup_2012=pd.read_csv(\"data/g12.csv\").set_index('State')\n",
        "gallup_2012[\"Unknown\"] = 100 - gallup_2012.Democrat - gallup_2012.Republican\n",
        "gallup_2012.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZwiXFcefO26",
        "colab_type": "text"
      },
      "source": [
        "Each row lists a state, the percent of surveyed individuals who identify as Democrat/Republican, the percent whose identification is unknown or who haven't made an affiliation yet, the margin between Democrats and Republicans (`Dem_Adv`: the percentage identifying as Democrats minus the percentage identifying as Republicans), and the number `N` of people surveyed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dZN8YZxfO27",
        "colab_type": "text"
      },
      "source": [
        "We can construct sub-dataframes by using an array-like indexing syntax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2sMoEBMfO27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gallup_2012[['Dem_Adv', 'Unknown']].head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yYVH6cCfO2-",
        "colab_type": "text"
      },
      "source": [
        "The most obvious source of error in the Gallup data is the finite sample size -- Gallup did not poll *everybody* in America, and thus the party affilitions are subject to sampling errors. How much uncertainty does this introduce? Lets estimate the sampling error using what we learnt in the last section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2-hX3bAfO2-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gallup_2012[\"SE_percentage\"]=100.0*np.sqrt((gallup_2012.Democrat/100.)*((100. - gallup_2012.Democrat)/100.)/(gallup_2012.N))\n",
        "gallup_2012.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gScWzAQcfO3A",
        "colab_type": "text"
      },
      "source": [
        "On their [webpage](http://www.gallup.com/poll/156437/heavily-democratic-states-concentrated-east.aspx#2) discussing these data, Gallup notes that the sampling error for the states is between 3 and 6%, with it being 3% for most states. This is more than what we find, so lets go with what Gallup says.\n",
        "\n",
        "We now use Gallup's estimate of 3% to build a Gallup model with some uncertainty. We will, using the CLT, assume that the sampling distribution of the Obama win percentage is a gaussian with mean the democrat percentage and standard error the sampling error of 3\\%. \n",
        "\n",
        "We'll build the model in the function `uncertain_gallup_model`, and return a forecast where the probability of an Obama victory is given by the probability that a sample from the `Dem_Adv` Gaussian is positive.\n",
        "\n",
        "To do this we simply need to find the area under the curve of a Gaussian that is on the positive side of the x-axis.\n",
        "The probability that a sample from a Gaussian with mean $\\mu$ and standard deviation $\\sigma$ exceeds a threhold $z$ can be found using $1$ minus the Cumulative Distribution Function, or the survival function of a Gaussian:\n",
        "\n",
        "$$ SF(z) = 1 - CDF(z) $$\n",
        "\n",
        "$$\n",
        "1 - CDF(z) = \\frac1{2}\\left(1 + {\\mathrm erf}\\left(\\frac{z - \\mu}{\\sqrt{2 \\sigma^2}}\\right)\\right) \n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNeOS2BDfO3B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from scipy.special import erf\n",
        "def uncertain_gallup_model(gallup):\n",
        "    sigma = 3\n",
        "    #prob =  .5 * (1 + erf(gallup.Dem_Adv / np.sqrt(2 * sigma**2)))\n",
        "    prob = norm.sf(0, gallup.Dem_Adv, sigma)\n",
        "    return pd.DataFrame(dict(Obama=prob), index=gallup.index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSQrNc5NfO3E",
        "colab_type": "text"
      },
      "source": [
        "We now have two dataframes with state names as an index. Lets **join** these to produce a wider one with all the data we have. This is identical to a SQL inner join."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmZHDGq3fO3E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = uncertain_gallup_model(gallup_2012)\n",
        "model = model.join(electoral_votes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPEbTCQefO3M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQqty3BzfO3P",
        "colab_type": "text"
      },
      "source": [
        "You can make simple plots very easily with pandas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_e4WoJIfO3P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.Votes.hist(bins=15);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4Pd-GK2fO3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(9, 18))\n",
        "gallup_2012.sort_values('Dem_Adv')['Dem_Adv'].plot(kind=\"barh\", color=\"r\");"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8tmm5R8fO3T",
        "colab_type": "text"
      },
      "source": [
        "What exactly is in a Pandas Series? Lets see:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQR6wodnfO3U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "votes_series = model.Votes\n",
        "votes_series"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3B-nN21fO3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "type(votes_series)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUSbsrFCfO3Y",
        "colab_type": "text"
      },
      "source": [
        "We might want to get back to numpy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7kEVnaFfO3Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "votes_series.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtKVme1zfO3c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model[['Obama', 'Votes']].values # get 2d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpVAITUDfO3e",
        "colab_type": "text"
      },
      "source": [
        "## Simulate!\n",
        "\n",
        "We plot a map of these probabilities as before, run the simulation, and display the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsTqcFfxfO3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = simulate_election(model, 10000)\n",
        "prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYRxWrYyfO3i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from statesplot import make_map, load_states_geom\n",
        "s2p = load_states_geom(\"data/us-states.json\")\n",
        "make_map(s2p, model.Obama, \"P(Obama): Gallup\");"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1P2ZCucfO3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_simulation(simulation):    \n",
        "    plt.hist(simulation, bins=np.arange(200, 538, 1), \n",
        "             label='simulations', align='left', normed=True)\n",
        "    plt.axvline(332, 0, .5, color='r', label='Actual Outcome')\n",
        "    plt.axvline(269, 0, .5, color='k', label='Victory Threshold')\n",
        "    p05 = np.percentile(simulation, 5.)\n",
        "    p95 = np.percentile(simulation, 95.)\n",
        "    iq = int(p95 - p05)\n",
        "    pwin = ((simulation >= 269).mean() * 100)\n",
        "    plt.title(\"Chance of Obama Victory: %0.2f%%, Spread: %d votes\" % (pwin, iq))\n",
        "    plt.legend(frameon=False, loc='upper left')\n",
        "    plt.xlabel(\"Obama Electoral College Votes\")\n",
        "    plt.ylabel(\"Probability\")\n",
        "    sns.despine()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6HfnldBfO3p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with sns.plotting_context('poster'):\n",
        "    plot_simulation(prediction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SP4z0v3XfO3r",
        "colab_type": "text"
      },
      "source": [
        "The predictive distribution is consistent with the real data -- the real outcome seems like a typical outcome according to the model. The accuracy is not very good as the center of the distribution falls fairly far from the observed outcome, but the precision is only marginally worse than in the predictwise case.\n",
        "\n",
        "But note that we used the Gallup voter self-identification from January to June to predict this, so we do not expect to do too well. And even though this is probably not a very unbiased sample, it still makes us wonder: at 97\\% of simulations showing a win for Obama, why did Romney ever think he had a chance?"
      ]
    }
  ]
}